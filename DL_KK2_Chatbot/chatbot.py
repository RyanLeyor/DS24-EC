import os
import numpy as np
from dotenv import load_dotenv
from pypdf import PdfReader
from google.genai import types
from google import genai

# Ladda API nyckeln f칬r Google gemini AI 

client = genai.Client(api_key="AIzaSyALzrmgZlrjxoeO-XOxemrT_0X8vbBju7U")

# Anv칛nda RAG-Teknik f칬r att h칛mta infromation fr친n text-data genom ett PDF-dokument
def extract_text(pdf_path):
    # L칛ser in text fr친n PDF-filen
    reader = PdfReader(pdf_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

#Dela upp texten i mindre delar med "Chunkning". Nedan skapas chunks som inneh친ller 1000 tecken med ett 칬verlapp p친 200 tecken.
def chunk_text(text, n =500, overlap=100):
    chunks = []
    for i in range(0, len(text), n - overlap):
        chunks.append(text[i:i + n])
    print(f"Antal chunks: {len(chunks)}.")
    return chunks

# Skapa embedding, numerisk representation av texten, f칬r att en dator ska kunna f칬rst친 betydelse av texten.
def create_embeddings(texts):
    """
    Skapar embeddings f칬r en lista av texter.
    """
    return [
        client.models.embed_content(
            model="text-embedding-004",
            contents=text,
            config=types.EmbedContentConfig(task_type="SEMANTIC_SIMILARITY")
        ).embeddings[0].values
        for text in texts
    ]


# Skapa en semantisk s칬kning med cosine similarity f칬r att hitt
def cosine_similarity(vec1, vec2):
     """
     r칛kna ut likheten mellan tv친 vektorer genom att j칛mf칬ra deras riktning, ju mer lika riktning desto mer lika 칛r de.
     ska anv칛ndas f칬r att hitta chunks i instruktionen som 칛r mest lika fr친gan.
     """

     return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

def semantic_search(query, chunks, embeddings, k=5):
    """
    G칬r embedding av fr친gan och j칛mf칬ra den med alla chunks f칬r att hitta mest likhet
    """
    query_embedding = create_embeddings([query])[0]
    scores = [(i, cosine_similarity(query_embedding, emb)) for i, emb in enumerate(embeddings)]
    top_indices = sorted(scores, key=lambda x: x[1], reverse=True)[:k]
    return [chunks[i] for i, _ in top_indices]

# Generara svar baserat p친 kotext fr친n PDF dokumentet
system_prompt = """
Du 칛r en hj칛lpsam AI-assistent. Anv칛nd informationen i kontexten nedan f칬r att besvara fr친gan s친 bra du kan.
Om inget svar finns, s칛g att du inte vet.
"""


def generate_response(query, chunks, embeddings):
    context = "\n".join(semantic_search(query, chunks, embeddings))

    user_prompt = f"Fr친ga: {query}\n\nKontekst:\n{context}"
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        config=types.GenerateContentConfig(system_instruction=system_prompt),
        contents=user_prompt
    )
    return response.text

#skapa en textbaserad chattbot som kan k칬ras i terminalen

if __name__ == "__main__":
    print(" Chattbot (skriv 'q' f칬r att avsluta)")

  
    pdf_instruktion = (r"D:\Utbildning\VSCODE codes\instruktion.pdf")

    pdf_text = extract_text(pdf_instruktion)

    " === denna kod nedan anv칛ndes endast f칬r att kontrollera att texten har extraherats korrekt ==="
   # print("\n游댍 UTDRAGEN TEXT (f칬rsta 1000 tecken):\n")
   # print(pdf_text[:1000])
   # print("\n============================\n") 

# Dela upp texten i mindre delar "Chunks" f칬r att hantera stora textm칛ngder
    chunks = chunk_text(pdf_text)
    embeddings = [create_embeddings([chunk])[0] for chunk in chunks]

    # Starta en enkel terminalbaserad chattbot
    while True:
        prompt = input("Anv칛ndare: ")
        if prompt == 'q':
            break
        else:
            response = generate_response(prompt, chunks, embeddings)
            print(f"chattbot: " + response)


# REFLEKTION 

"""
Anv칛ndning i verkligeheten:
Denna chattbot skulle kunna anv칛ndas av nyanst칛llda eller operat칬rer f칬r att snabbt hitta svar f칬r instruktioner och riktlinjer i hantering av ett moment

M칬jligheter:
Effektiv och snabb 친tkomst till information
F칛rre fel vid tolkning av instruktioner
M칬jlighet till att integrera med fler instruktioner och dokument

Utmaningar:
Tydlighet i dokumentationen kan p친verka svarens kvalitet
Om dokument 칛ndras m친ste chattboten uppdateras
Svar kan vara begr칛nsade till det som finns i dokumentet, vilket kan leda till frustration om information saknas
 """